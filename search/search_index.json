{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Decoding DevOps \u00b6 For full documentation visit Decoding DevOps","title":"Home"},{"location":"#decoding-devops","text":"For full documentation visit Decoding DevOps","title":"Decoding DevOps"},{"location":"devops/ansible/","text":"Ansible \u00b6 Installing Ansible Ubuntu CentOS sudo apt update sudo apt install software-properties-common sudo add-apt-repository --yes --update ppa:ansible/ansible sudo apt install ansible ansible --version sudo yum install epel-release sudo yum install ansible ansible --version Sample Inventory File \u00b6 Inventory ##Host Level webserver01 ansible_host =< Private IP > webserver02 ansible_host =< Private IP > webserver03 ansible_host =< Private IP > dbserver01 ansible_host =< Private IP > dbserver02 ansible_host =< Private IP > ansible_user = ubuntu ##Group Level [ Group1 ] webserverserver01 webserverserver02 webserverserver03 [ Group2 ] dbserver01 dbserver02 ##Parent Level [ dc_mumbai : children ] webservergrp dbsrvgrp ##Variables [ dc_mumbai : vars ] ansible_user =< user > ansible_ssh_private_key_file =< key - path > Info Host level has the Highest priority , If you mention anything like username or Keyfile etc. It will take only which are mentioned in the host level. Ansible Commands \u00b6 To test the connection of particular Remote Machine ansible -i <Inventoryfile path> -m ping <hostname> To test the connection of particular Group of Remote Machines ansible -i <Inventoryfile path> -m ping <Groupname> To test the connection of All Remote Machine ansible -i <Inventoryfile path> -m ping all To see details about the machine ansible -i <Inventoryfile path> -m setup <hostname> Some Example Ad hoc Commands \u00b6 Ad hoc Commands Copy files to Remote machines name starts with web ansible -i <Inventoryfile path> -m copy -a \"src=index,html dest=/var/www/html/index.html\" 'web*' --become Installing httpd in centos Remote machine ansible -i <Inventoryfile path> -m yum -a \"name=httpd state=present\" websrvgrp --become Start & Enable httpd in centos Remote machine ansible -i <Inventoryfile path> -m service -a \"name=httpd state=started enabled=yes\" websrvgrp --become Info Ansible Playbooks should be with .yml or .yaml Extension for example vim sample.yml Playbook For Creating Files & Directories \u00b6 Sample Ansible Playbooks - name : Creating Files & Directories hosts : <host> become : yes tasks : - name : Creating a Directory file : path : /tmp/welcome state : directory - name : Creating a File file : path : /tmp/sample.txt state : touch To Execute the playbook ansible-playbook -i <Inventory file path> sample.yml Creating Playbook For Installing Httpd service in remote machines with start and enable and copying index.html files from local machine to remote machine \u00b6 - name : Install httpd and starting the service hosts : all tasks : - name : Installing the Apache package yum : name : httpd state : present - name : Starting service service : name : httpd state : started enabled : yes - name : Copy file with owner and permissions copy : src : ./index.html dest : /var/www/html/index.html - name : Restarting service service : name : httpd state : restarted Ansible Configuration File \u00b6 Note You should save the configuration file with name ansible.cfg vim ansible.cfg Ansible Configuration File [ defaults ] host_key_checking = False inventory = <Inventory File Path> timeout = 20 log_path = /var/log/ansible_world.log remote_port = 22 remote_user = <username> [ privilege_escalation ] become = True become_method = sudo become_user = root become_ask_pass = False","title":"Ansible"},{"location":"devops/ansible/#ansible","text":"Installing Ansible Ubuntu CentOS sudo apt update sudo apt install software-properties-common sudo add-apt-repository --yes --update ppa:ansible/ansible sudo apt install ansible ansible --version sudo yum install epel-release sudo yum install ansible ansible --version","title":"Ansible"},{"location":"devops/ansible/#sample-inventory-file","text":"Inventory ##Host Level webserver01 ansible_host =< Private IP > webserver02 ansible_host =< Private IP > webserver03 ansible_host =< Private IP > dbserver01 ansible_host =< Private IP > dbserver02 ansible_host =< Private IP > ansible_user = ubuntu ##Group Level [ Group1 ] webserverserver01 webserverserver02 webserverserver03 [ Group2 ] dbserver01 dbserver02 ##Parent Level [ dc_mumbai : children ] webservergrp dbsrvgrp ##Variables [ dc_mumbai : vars ] ansible_user =< user > ansible_ssh_private_key_file =< key - path > Info Host level has the Highest priority , If you mention anything like username or Keyfile etc. It will take only which are mentioned in the host level.","title":"Sample Inventory File"},{"location":"devops/ansible/#ansible-commands","text":"To test the connection of particular Remote Machine ansible -i <Inventoryfile path> -m ping <hostname> To test the connection of particular Group of Remote Machines ansible -i <Inventoryfile path> -m ping <Groupname> To test the connection of All Remote Machine ansible -i <Inventoryfile path> -m ping all To see details about the machine ansible -i <Inventoryfile path> -m setup <hostname>","title":"Ansible Commands"},{"location":"devops/ansible/#some-example-ad-hoc-commands","text":"Ad hoc Commands Copy files to Remote machines name starts with web ansible -i <Inventoryfile path> -m copy -a \"src=index,html dest=/var/www/html/index.html\" 'web*' --become Installing httpd in centos Remote machine ansible -i <Inventoryfile path> -m yum -a \"name=httpd state=present\" websrvgrp --become Start & Enable httpd in centos Remote machine ansible -i <Inventoryfile path> -m service -a \"name=httpd state=started enabled=yes\" websrvgrp --become Info Ansible Playbooks should be with .yml or .yaml Extension for example vim sample.yml","title":"Some Example Ad hoc Commands"},{"location":"devops/ansible/#playbook-for-creating-files-directories","text":"Sample Ansible Playbooks - name : Creating Files & Directories hosts : <host> become : yes tasks : - name : Creating a Directory file : path : /tmp/welcome state : directory - name : Creating a File file : path : /tmp/sample.txt state : touch To Execute the playbook ansible-playbook -i <Inventory file path> sample.yml","title":"Playbook For Creating Files &amp; Directories"},{"location":"devops/ansible/#creating-playbook-for-installing-httpd-service-in-remote-machines-with-start-and-enable-and-copying-indexhtml-files-from-local-machine-to-remote-machine","text":"- name : Install httpd and starting the service hosts : all tasks : - name : Installing the Apache package yum : name : httpd state : present - name : Starting service service : name : httpd state : started enabled : yes - name : Copy file with owner and permissions copy : src : ./index.html dest : /var/www/html/index.html - name : Restarting service service : name : httpd state : restarted","title":"Creating Playbook For Installing Httpd service in remote machines with start and enable and copying index.html files from local machine to remote machine"},{"location":"devops/ansible/#ansible-configuration-file","text":"Note You should save the configuration file with name ansible.cfg vim ansible.cfg Ansible Configuration File [ defaults ] host_key_checking = False inventory = <Inventory File Path> timeout = 20 log_path = /var/log/ansible_world.log remote_port = 22 remote_user = <username> [ privilege_escalation ] become = True become_method = sudo become_user = root become_ask_pass = False","title":"Ansible Configuration File"},{"location":"devops/aws-cli/","text":"AWS CLI (Command Line Interface) \u00b6 Setting up IAM user \u00b6 Creating User with Access-key \u00b6 Set permissions & Attaching Policies \u00b6 Installing AWS-CLI \u00b6 sudo -i sudo apt update apt install awscli -y Configure AWS CLI with IAM user Credentials with specific Region \u00b6 aws configure Once it is done try some aws cli commands like aws s3 ls If u have any buckets in your s3 it will list EC2 \u2013 Elastic Compute Cloud \u00b6 Create a key pair \u00b6 aws ec2 create-key-pair --key-name <keypair-Name> --query 'KeyMaterial' --output text > <keypair-Name.pem> Delete a key pair \u00b6 To delete a key pair, run the aws ec2 delete-key-pair command, substituting MyKeyPair with the name of the pair to delete. aws ec2 delete-key-pair --key-name <keypair-Name> Create a Security Group & Adding Inbound rules \u00b6 aws ec2 create-security-group --group-name <security grp Name> --description \"<Description>\" curl https://checkip.amazonaws.com aws ec2 authorize-security-group-ingress --group-id <security group Id> --protocol tcp --port <port Number> --cidr <ip address> aws ec2 authorize-security-group-ingress --group-id <security grp Id>--protocol tcp --port 22 -8000 --cidr 0 .0.0.0/0 To view the initial information for my-sg, run the aws ec2 describe-security-groups command. For an EC2-Classic security group, you can reference it by its name. aws ec2 describe-security-groups --group-names <security grp Name> Delete your security group \u00b6 The following command example deletes the EC2-Classic security group named. aws ec2 delete-security-group --group-name <security grp Name> Launch Instance \u00b6 You can use the following command to launch a t2.micro instance in EC2-Classic. Replace the italicized parameter values with your own. You can get the ami Id\u2019s from documentation or console for your required Instance. aws ec2 run-instances --image-id <ami-Id> --count 1 --instance-type <type> --key-name <keypair-Name> --security-groups <security grp Name> Add a tag to your Instance \u00b6 aws ec2 create-tags --resources <Instance-Id>--tags Key = Name,Value = <value> Terminate your Instance \u00b6 To delete an instance, you use the command aws ec2 terminate-instances to delete it. aws ec2 terminate-instances --instance-ids <Instance-Id> Create Launch Template \u00b6 aws ec2 create-launch-template --launch-template-name <Name> \":[{\" AssociatePublicIpAddress \":true,\" DeviceIndex \":0,\" Ipv6AddressCount \":1,\" SubnetId \":\" pe \":\" <Instance type \",\" TagSpecifications \":[{\" ResourceType \":\" instance \",\" Tags \":[{\" Key \":\" Name \",\" Value \":\" <value> \"}]}]}' Delete Launch Template \u00b6 aws ec2 delete-launch-template --launch-template-id < template id> --region <region> Creating Auto-Scaling group \u00b6 aws autoscaling create-auto-scaling-group --auto-scaling-group-name <Name> --launch-LaunchTemplateId = <template \u2013 id > --min-size 2 --max-size 5 --vpc-zone-identifier \"subnet1-id,subnet2-id,subnet3-id\" Delete your Auto-Scaling Group \u00b6 aws autoscaling delete-auto-scaling-group --auto-scaling-group-name < Auto -Scaling group Name > EBS \u2013 Elastic Block Storage \u00b6 Create EBS Volume \u00b6 To create an empty General Purpose SSD (gp2) volume aws ec2 create-volume --volume-type <volume type> --size <size in number> --availability-zone <zone> To create an encrypted volume \u00b6 aws ec2 create-volume --volume-type <volume type> --size <size in number> --encrypted --availability-zone <zone> To create a volume with tags \u00b6 aws ec2 create-tags --resources <volume-id> --tags Key = Name,Value = <value> To Delete a Volume \u00b6 aws ec2 delete-volume --volume-id <volume Id> Output Output: None To create a snapshot \u00b6 This example command creates a snapshot of the volume with a volume ID of and a short description to identify the snapshot. aws ec2 create-snapshot --volume-id <volume Id> --description \"<Description>\" To create a snapshot with tags \u00b6 aws ec2 create-snapshot --volume-id <volume Id> --description 'Prod backup' --tag-specifications 'ResourceType=snapshot,Tags=[{Key=Name,Value=<value>},{Key=Database,Value=Mysql}]' To allocate an Elastic IP address for EC2-Classic \u00b6 The following allocate-address example allocates an Elastic IP address to use with an instance in EC2-Classic. aws ec2 allocate-address ELB \u2013 Elastic Load Balancer \u00b6 Create-load-balancer \u00b6 To create an Application load balancer \u00b6 The below commands to find subnet id & Instance Id aws ec2 describe-subnets aws ec2 describe-instances aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id> <subnet-Id> To create an Network load balancer \u00b6 aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id> To register instances with a load balancer \u00b6 aws elb register-instances-with-load-balancer --load-balancer-name <Load balancer Name> --instances <Instance-Id> To Delete a Specific Load balancer \u00b6 aws elbv2 delete-load-balancer --load-balancer-arn <arn end point> RDS - Relational Database Service \u00b6 Create-db-Instance \u00b6 aws rds create-db-instance --db-instance-identifier <db - Name> --db-instance-class <db.type> --engine <Database Engine> --master-username <username> --master-user-password <password> --allocated-storage <storage in numbers> To delete your db-Instance \u00b6 aws rds delete-db-instance --db-instance-identifier <db - Name> --final-db-snapshot-identifier <db - Name>-final-snap S3 \u2013 Simple Storage Service \u00b6 List Buckets & Objects \u00b6 To list your buckets, folders, or objects, use the s3 ls command. Using the command without a target or options lists all buckets. aws s3 ls aws s3 ls s3://<bucket name> Create a bucket \u00b6 Use the s3 mb command to make a bucket. Bucket names must be globally unique (unique across all of Amazon S3) and should be DNS compliant. aws s3 mb s3:// <bucket name> Copy objects \u00b6 Use the s3 cp command to copy objects from a bucket or a local directory aws s3 cp <file> s3:// <bucket name> aws s3 cp s3://< source bucket/file> s3://<destination-bucket> Move objects \u00b6 Use the s3 mv command to move objects from a bucket or a local directory. aws s3 mv < local file> s3:// <bucket name> aws s3 mv s3:// < source bucket/file> s3://<destination-bucket> Sync Objects \u00b6 aws s3 sync . s3://<bucket name> Delete Objects \u00b6 aws s3 rm s3://<bucket name/file> --recursive Empty Bucket \u00b6 aws s3 rm s3://<bucket name> --recursive Delete Bucket \u00b6 aws s3 rb s3://<bucket name> VPC \u2013 Virtual Private Cloud \u00b6 To create a VPC and subnets using the AWS CLI \u00b6 Create a VPC with a 10.0.0.0/16 CIDR block using the following create-vpc command. \u00b6 aws ec2 create-vpc --cidr-block <Ip address> --query Vpc.VpcId --output text Using the VPC ID from the previous step, create a subnet with a 10.0.1.0/24 CIDR block using the following create-subnet command. \u00b6 aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address> Create a second subnet in your VPC with a 10.0.2.0/24 CIDR block. \u00b6 aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address> Create an internet gateway using the following create-internet-gateway command. \u00b6 aws ec2 create-internet-gateway --query InternetGateway.InternetGatewayId --output text Using the ID from the previous step, attach the internet gateway to your VPC using the following attach-internet-gateway command. \u00b6 aws ec2 attach-internet-gateway --vpc-id <vpc - Id>--internet-gateway-id <IGW - Id> Create a custom route table for your VPC using the following create-route-table command. \u00b6 aws ec2 create-route-table --vpc-id <vpc - Id>--query RouteTable.RouteTableId --output text Create a route in the route table that points all traffic (0.0.0.0/0) to the internet gateway using the following create-route command. \u00b6 aws ec2 create-route --route-table-id <route table - Id>--destination-cidr-block 0 .0.0.0/0 --gateway-id <Igw - Id> You can describe the route table using the following describe-route-tables command. \u00b6 aws ec2 describe-route-tables --route-table-id <route table - Id> The route table is currently not associated with any subnet. You need to associate it with a subnet in your VPC so that traffic from that subnet is routed to the internet gateway. \u00b6 aws ec2 describe-subnets --filters \"Name=vpc-id,Values=<vpc \u2013Id> --query \" Subnets [ * ] . { ID:SubnetId,CIDR:CidrBlock } \" You can choose which subnet to associate with the custom route table, for example, subnet-0c312202b3f26703a, and associate it using the associate-route-table command. This subnet is your public subnet. \u00b6 aws ec2 associate-route-table --subnet-id <subnet-Id> --route-table-id <route table - Id> CLEAN UP \u00b6 Delete your custom route table: \u00b6 aws ec2 delete-route-table --route-table-id <route table - Id> Delete your subnets: \u00b6 aws ec2 delete-subnet --subnet-id <subnet-Id> Detach your internet gateway from your VPC: \u00b6 aws ec2 detach-internet-gateway --internet-gateway-id <Igw -Id> --vpc-id <vpc- Id> Delete your internet gateway: \u00b6 aws ec2 delete-internet-gateway --internet-gateway-id <Igw - Id> Delete your VPC: \u00b6 aws ec2 delete-vpc --vpc-id <vpc- Id> Cloud Watch \u00b6 Creating Alarm \u00b6 aws cloudwatch put-metric-alarm --alarm-name <Alarm name> --alarm-description \"<Description>\" --metric-name <Metric> --namespace AWS/EC2 --statistic Average --period 300 --threshold < 70 > --comparison-operator <GreaterThanThreshold> --dimensions \"Name=InstanceId,Value=<Id>\" --evaluation-periods 2 --alarm-actions <SNS \u2013 arn > --unit Percent Delete Your Alarm \u00b6 aws cloudwatch delete-alarms --alarm-names <Alarm name> Disable your Alarm \u00b6 aws cloudwatch disable-alarm-actions --alarm-names <Alarm name> Enable your Alarm \u00b6 aws cloudwatch enable-alarm-actions --alarm-names <Alarm name>","title":"AWS"},{"location":"devops/aws-cli/#aws-cli-command-line-interface","text":"","title":"AWS CLI (Command Line Interface)"},{"location":"devops/aws-cli/#setting-up-iam-user","text":"","title":"Setting up IAM user"},{"location":"devops/aws-cli/#creating-user-with-access-key","text":"","title":"Creating User with Access-key"},{"location":"devops/aws-cli/#set-permissions-attaching-policies","text":"","title":"Set permissions &amp; Attaching Policies"},{"location":"devops/aws-cli/#installing-aws-cli","text":"sudo -i sudo apt update apt install awscli -y","title":"Installing AWS-CLI"},{"location":"devops/aws-cli/#configure-aws-cli-with-iam-user-credentials-with-specific-region","text":"aws configure Once it is done try some aws cli commands like aws s3 ls If u have any buckets in your s3 it will list","title":"Configure AWS CLI with IAM user Credentials with specific Region"},{"location":"devops/aws-cli/#ec2-elastic-compute-cloud","text":"","title":"EC2 \u2013 Elastic Compute Cloud"},{"location":"devops/aws-cli/#create-a-key-pair","text":"aws ec2 create-key-pair --key-name <keypair-Name> --query 'KeyMaterial' --output text > <keypair-Name.pem>","title":"Create a key pair"},{"location":"devops/aws-cli/#delete-a-key-pair","text":"To delete a key pair, run the aws ec2 delete-key-pair command, substituting MyKeyPair with the name of the pair to delete. aws ec2 delete-key-pair --key-name <keypair-Name>","title":"Delete a key pair"},{"location":"devops/aws-cli/#create-a-security-group-adding-inbound-rules","text":"aws ec2 create-security-group --group-name <security grp Name> --description \"<Description>\" curl https://checkip.amazonaws.com aws ec2 authorize-security-group-ingress --group-id <security group Id> --protocol tcp --port <port Number> --cidr <ip address> aws ec2 authorize-security-group-ingress --group-id <security grp Id>--protocol tcp --port 22 -8000 --cidr 0 .0.0.0/0 To view the initial information for my-sg, run the aws ec2 describe-security-groups command. For an EC2-Classic security group, you can reference it by its name. aws ec2 describe-security-groups --group-names <security grp Name>","title":"Create a Security Group &amp; Adding Inbound rules"},{"location":"devops/aws-cli/#delete-your-security-group","text":"The following command example deletes the EC2-Classic security group named. aws ec2 delete-security-group --group-name <security grp Name>","title":"Delete your security group"},{"location":"devops/aws-cli/#launch-instance","text":"You can use the following command to launch a t2.micro instance in EC2-Classic. Replace the italicized parameter values with your own. You can get the ami Id\u2019s from documentation or console for your required Instance. aws ec2 run-instances --image-id <ami-Id> --count 1 --instance-type <type> --key-name <keypair-Name> --security-groups <security grp Name>","title":"Launch Instance"},{"location":"devops/aws-cli/#add-a-tag-to-your-instance","text":"aws ec2 create-tags --resources <Instance-Id>--tags Key = Name,Value = <value>","title":"Add a tag to your Instance"},{"location":"devops/aws-cli/#terminate-your-instance","text":"To delete an instance, you use the command aws ec2 terminate-instances to delete it. aws ec2 terminate-instances --instance-ids <Instance-Id>","title":"Terminate your Instance"},{"location":"devops/aws-cli/#create-launch-template","text":"aws ec2 create-launch-template --launch-template-name <Name> \":[{\" AssociatePublicIpAddress \":true,\" DeviceIndex \":0,\" Ipv6AddressCount \":1,\" SubnetId \":\" pe \":\" <Instance type \",\" TagSpecifications \":[{\" ResourceType \":\" instance \",\" Tags \":[{\" Key \":\" Name \",\" Value \":\" <value> \"}]}]}'","title":"Create Launch Template"},{"location":"devops/aws-cli/#delete-launch-template","text":"aws ec2 delete-launch-template --launch-template-id < template id> --region <region>","title":"Delete Launch Template"},{"location":"devops/aws-cli/#creating-auto-scaling-group","text":"aws autoscaling create-auto-scaling-group --auto-scaling-group-name <Name> --launch-LaunchTemplateId = <template \u2013 id > --min-size 2 --max-size 5 --vpc-zone-identifier \"subnet1-id,subnet2-id,subnet3-id\"","title":"Creating Auto-Scaling group"},{"location":"devops/aws-cli/#delete-your-auto-scaling-group","text":"aws autoscaling delete-auto-scaling-group --auto-scaling-group-name < Auto -Scaling group Name >","title":"Delete your Auto-Scaling Group"},{"location":"devops/aws-cli/#ebs-elastic-block-storage","text":"","title":"EBS \u2013 Elastic Block Storage"},{"location":"devops/aws-cli/#create-ebs-volume","text":"To create an empty General Purpose SSD (gp2) volume aws ec2 create-volume --volume-type <volume type> --size <size in number> --availability-zone <zone>","title":"Create EBS Volume"},{"location":"devops/aws-cli/#to-create-an-encrypted-volume","text":"aws ec2 create-volume --volume-type <volume type> --size <size in number> --encrypted --availability-zone <zone>","title":"To create an encrypted volume"},{"location":"devops/aws-cli/#to-create-a-volume-with-tags","text":"aws ec2 create-tags --resources <volume-id> --tags Key = Name,Value = <value>","title":"To create a volume with tags"},{"location":"devops/aws-cli/#to-delete-a-volume","text":"aws ec2 delete-volume --volume-id <volume Id> Output Output: None","title":"To Delete a Volume"},{"location":"devops/aws-cli/#to-create-a-snapshot","text":"This example command creates a snapshot of the volume with a volume ID of and a short description to identify the snapshot. aws ec2 create-snapshot --volume-id <volume Id> --description \"<Description>\"","title":"To create a snapshot"},{"location":"devops/aws-cli/#to-create-a-snapshot-with-tags","text":"aws ec2 create-snapshot --volume-id <volume Id> --description 'Prod backup' --tag-specifications 'ResourceType=snapshot,Tags=[{Key=Name,Value=<value>},{Key=Database,Value=Mysql}]'","title":"To create a snapshot with tags"},{"location":"devops/aws-cli/#to-allocate-an-elastic-ip-address-for-ec2-classic","text":"The following allocate-address example allocates an Elastic IP address to use with an instance in EC2-Classic. aws ec2 allocate-address","title":"To allocate an Elastic IP address for EC2-Classic"},{"location":"devops/aws-cli/#elb-elastic-load-balancer","text":"","title":"ELB \u2013 Elastic Load Balancer"},{"location":"devops/aws-cli/#create-load-balancer","text":"","title":"Create-load-balancer"},{"location":"devops/aws-cli/#to-create-an-application-load-balancer","text":"The below commands to find subnet id & Instance Id aws ec2 describe-subnets aws ec2 describe-instances aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id> <subnet-Id>","title":"To create an Application load balancer"},{"location":"devops/aws-cli/#to-create-an-network-load-balancer","text":"aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id>","title":"To create an Network load balancer"},{"location":"devops/aws-cli/#to-register-instances-with-a-load-balancer","text":"aws elb register-instances-with-load-balancer --load-balancer-name <Load balancer Name> --instances <Instance-Id>","title":"To register instances with a load balancer"},{"location":"devops/aws-cli/#to-delete-a-specific-load-balancer","text":"aws elbv2 delete-load-balancer --load-balancer-arn <arn end point>","title":"To Delete a Specific Load balancer"},{"location":"devops/aws-cli/#rds-relational-database-service","text":"","title":"RDS - Relational Database Service"},{"location":"devops/aws-cli/#create-db-instance","text":"aws rds create-db-instance --db-instance-identifier <db - Name> --db-instance-class <db.type> --engine <Database Engine> --master-username <username> --master-user-password <password> --allocated-storage <storage in numbers>","title":"Create-db-Instance"},{"location":"devops/aws-cli/#to-delete-your-db-instance","text":"aws rds delete-db-instance --db-instance-identifier <db - Name> --final-db-snapshot-identifier <db - Name>-final-snap","title":"To delete your db-Instance"},{"location":"devops/aws-cli/#s3-simple-storage-service","text":"","title":"S3 \u2013 Simple Storage Service"},{"location":"devops/aws-cli/#list-buckets-objects","text":"To list your buckets, folders, or objects, use the s3 ls command. Using the command without a target or options lists all buckets. aws s3 ls aws s3 ls s3://<bucket name>","title":"List Buckets &amp; Objects"},{"location":"devops/aws-cli/#create-a-bucket","text":"Use the s3 mb command to make a bucket. Bucket names must be globally unique (unique across all of Amazon S3) and should be DNS compliant. aws s3 mb s3:// <bucket name>","title":"Create a bucket"},{"location":"devops/aws-cli/#copy-objects","text":"Use the s3 cp command to copy objects from a bucket or a local directory aws s3 cp <file> s3:// <bucket name> aws s3 cp s3://< source bucket/file> s3://<destination-bucket>","title":"Copy objects"},{"location":"devops/aws-cli/#move-objects","text":"Use the s3 mv command to move objects from a bucket or a local directory. aws s3 mv < local file> s3:// <bucket name> aws s3 mv s3:// < source bucket/file> s3://<destination-bucket>","title":"Move objects"},{"location":"devops/aws-cli/#sync-objects","text":"aws s3 sync . s3://<bucket name>","title":"Sync Objects"},{"location":"devops/aws-cli/#delete-objects","text":"aws s3 rm s3://<bucket name/file> --recursive","title":"Delete Objects"},{"location":"devops/aws-cli/#empty-bucket","text":"aws s3 rm s3://<bucket name> --recursive","title":"Empty Bucket"},{"location":"devops/aws-cli/#delete-bucket","text":"aws s3 rb s3://<bucket name>","title":"Delete Bucket"},{"location":"devops/aws-cli/#vpc-virtual-private-cloud","text":"","title":"VPC \u2013 Virtual Private Cloud"},{"location":"devops/aws-cli/#to-create-a-vpc-and-subnets-using-the-aws-cli","text":"","title":"To create a VPC and subnets using the AWS CLI"},{"location":"devops/aws-cli/#create-a-vpc-with-a-1000016-cidr-block-using-the-following-create-vpc-command","text":"aws ec2 create-vpc --cidr-block <Ip address> --query Vpc.VpcId --output text","title":"Create a VPC with a 10.0.0.0/16 CIDR block using the following create-vpc command."},{"location":"devops/aws-cli/#using-the-vpc-id-from-the-previous-step-create-a-subnet-with-a-1001024-cidr-block-using-the-following-create-subnet-command","text":"aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address>","title":"Using the VPC ID from the previous step, create a subnet with a 10.0.1.0/24 CIDR block using the following create-subnet command."},{"location":"devops/aws-cli/#create-a-second-subnet-in-your-vpc-with-a-1002024-cidr-block","text":"aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address>","title":"Create a second subnet in your VPC with a 10.0.2.0/24 CIDR block."},{"location":"devops/aws-cli/#create-an-internet-gateway-using-the-following-create-internet-gateway-command","text":"aws ec2 create-internet-gateway --query InternetGateway.InternetGatewayId --output text","title":"Create an internet gateway using the following create-internet-gateway command."},{"location":"devops/aws-cli/#using-the-id-from-the-previous-step-attach-the-internet-gateway-to-your-vpc-using-the-following-attach-internet-gateway-command","text":"aws ec2 attach-internet-gateway --vpc-id <vpc - Id>--internet-gateway-id <IGW - Id>","title":"Using the ID from the previous step, attach the internet gateway to your VPC using the following attach-internet-gateway command."},{"location":"devops/aws-cli/#create-a-custom-route-table-for-your-vpc-using-the-following-create-route-table-command","text":"aws ec2 create-route-table --vpc-id <vpc - Id>--query RouteTable.RouteTableId --output text","title":"Create a custom route table for your VPC using the following create-route-table command."},{"location":"devops/aws-cli/#create-a-route-in-the-route-table-that-points-all-traffic-00000-to-the-internet-gateway-using-the-following-create-route-command","text":"aws ec2 create-route --route-table-id <route table - Id>--destination-cidr-block 0 .0.0.0/0 --gateway-id <Igw - Id>","title":"Create a route in the route table that points all traffic (0.0.0.0/0) to the internet gateway using the following create-route command."},{"location":"devops/aws-cli/#you-can-describe-the-route-table-using-the-following-describe-route-tables-command","text":"aws ec2 describe-route-tables --route-table-id <route table - Id>","title":"You can describe the route table using the following describe-route-tables command."},{"location":"devops/aws-cli/#the-route-table-is-currently-not-associated-with-any-subnet-you-need-to-associate-it-with-a-subnet-in-your-vpc-so-that-traffic-from-that-subnet-is-routed-to-the-internet-gateway","text":"aws ec2 describe-subnets --filters \"Name=vpc-id,Values=<vpc \u2013Id> --query \" Subnets [ * ] . { ID:SubnetId,CIDR:CidrBlock } \"","title":"The route table is currently not associated with any subnet. You need to associate it with a subnet in your VPC so that traffic from that subnet is routed to the internet gateway."},{"location":"devops/aws-cli/#you-can-choose-which-subnet-to-associate-with-the-custom-route-table-for-example-subnet-0c312202b3f26703a-and-associate-it-using-the-associate-route-table-command-this-subnet-is-your-public-subnet","text":"aws ec2 associate-route-table --subnet-id <subnet-Id> --route-table-id <route table - Id>","title":"You can choose which subnet to associate with the custom route table, for example, subnet-0c312202b3f26703a, and associate it using the associate-route-table command. This subnet is your public subnet."},{"location":"devops/aws-cli/#clean-up","text":"","title":"CLEAN UP"},{"location":"devops/aws-cli/#delete-your-custom-route-table","text":"aws ec2 delete-route-table --route-table-id <route table - Id>","title":"Delete your custom route table:"},{"location":"devops/aws-cli/#delete-your-subnets","text":"aws ec2 delete-subnet --subnet-id <subnet-Id>","title":"Delete your subnets:"},{"location":"devops/aws-cli/#detach-your-internet-gateway-from-your-vpc","text":"aws ec2 detach-internet-gateway --internet-gateway-id <Igw -Id> --vpc-id <vpc- Id>","title":"Detach your internet gateway from your VPC:"},{"location":"devops/aws-cli/#delete-your-internet-gateway","text":"aws ec2 delete-internet-gateway --internet-gateway-id <Igw - Id>","title":"Delete your internet gateway:"},{"location":"devops/aws-cli/#delete-your-vpc","text":"aws ec2 delete-vpc --vpc-id <vpc- Id>","title":"Delete your VPC:"},{"location":"devops/aws-cli/#cloud-watch","text":"","title":"Cloud Watch"},{"location":"devops/aws-cli/#creating-alarm","text":"aws cloudwatch put-metric-alarm --alarm-name <Alarm name> --alarm-description \"<Description>\" --metric-name <Metric> --namespace AWS/EC2 --statistic Average --period 300 --threshold < 70 > --comparison-operator <GreaterThanThreshold> --dimensions \"Name=InstanceId,Value=<Id>\" --evaluation-periods 2 --alarm-actions <SNS \u2013 arn > --unit Percent","title":"Creating Alarm"},{"location":"devops/aws-cli/#delete-your-alarm","text":"aws cloudwatch delete-alarms --alarm-names <Alarm name>","title":"Delete Your Alarm"},{"location":"devops/aws-cli/#disable-your-alarm","text":"aws cloudwatch disable-alarm-actions --alarm-names <Alarm name>","title":"Disable your Alarm"},{"location":"devops/aws-cli/#enable-your-alarm","text":"aws cloudwatch enable-alarm-actions --alarm-names <Alarm name>","title":"Enable your Alarm"},{"location":"devops/docker-setup/","text":"Install Docker Engine & Docker-Compose on Ubuntu & CentOS \u00b6 Docker Setup Create a file name docker_setup.sh and copy the below script vim docker_setup.sh #!/bin/bash apt --help >>/dev/null if [ $? -eq 0 ] then echo \" INSTALLING DOCKER IN UBUNTU\" echo sudo apt update sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update sudo apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io -y sudo docker run hello-world else echo \" INSTALLING DOCKER IN CENTOS\" echo sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io -y sudo systemctl start docker sudo docker run hello-world fi echo \" Installing Docker Compose\" sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version Give Execute permission for script sudo chmod +x docker_setup.sh Now run the Script ./docker_setup.sh Docker Commands \u00b6 Docker Images List all images that are locally stored with the Docker Engine docker image ls Build an image from the Dockerfile in the current directory and tag the image docker build -t <imagename>:<tag> Delete an image from the local image store docker image rm <imagename>:<tag> Containers Run a container in interactive mode: docker run -it <imagename>:<tag> Run a container from the Image nginx:latest, name the running container \u201cweb\u201d and expose port 5000 externally, mapped to port 80 inside the container in detached mode. docker run --name web -d -p 5000 :80 nginx:latest Run a detached container in a previously created container network: docker network create <mynetwork> docker run --name web -d --net mynetwork -p 5000 :80 nginx:latest Follow the logs of a specific container: docker logs -f <container name or container container-id> List only active containers docker ps List all containers docker ps -a Stop a container docker stop <container name or container container-id> Stop a container (timeout = 1 second) docker stop -t1 Remove a stopped container docker rm <container name or container container-id> Force stop and remove a container docker rm -f <container name or container container-id> Remove all containers docker rm -f $( docker ps-aq ) Remove all stopped containers docker rm $( docker ps -q -f \u201cstatus = exited\u201d ) Execute a new process in an existing container:Execute and access bash inside a container docker exec -it <container name or container-id> bash To inspect the container docker inspect <container name or container container-id> Share To Establish Connection from local to Remote. login with your Dockerhub Credentials. docker login Pull an image from a registry docker pull <imagename>:<tag> Retag a local image with a new image name and tag docker tag myimage:1.0 myrepo/myimage:2.0 Push an image to a registry. docker push myrepo/myimage:2.0 Dockerfile Sample Dockerfile for Deploying a Staticwebsite. vim Dockerfile FROM centos:latest LABEL \"Author\" = \"saiteja\" LABEL \"Project\" = \"Wave\" RUN yum install httpd wget unzip -y RUN wget https://www.tooplate.com/zip-templates/2121_wave_cafe.zip RUN unzip 2121_wave_cafe.zip RUN cp -r 2121_wave_cafe/* /var/www/html/ CMD [ \"/usr/sbin/httpd\" , \"-D\" , \"FOREGROUND\" ] EXPOSE 80 WORKDIR /var/www/html VOLUME /var/log/httpd Build the image from the Docker file , Here Change my Name with your registery name and Image. docker build -t saitejairrinki/wavecafe:v1 . Run Container From the Image docker run --name wavecafe -d -p 9699 :80 saitejairrinki/wavecafe:v1 Now Access From the Browser, Make sure you have to allow the portnumber in my case 9699 in your security group if you are using cloud VM. Public-IPaddress:9699 Docker Image You can pull my image and you can also run container from my image without creating Dockerfile. docker pull saitejairrinki/wavecafe:v1 docker run --name wavecafe -d -p 9999 :80 saitejairrinki/wavecafe:v1 Now Access From the Browser, Make sure you have to allow the portnumber in my case 9999 in your security group if you are using cloud VM. Public-IPaddress:9999 Docker Volume Creating a Seperate Directory to Store Container data mkdir mountbind Now link your Directory while running the container docker run --name db01 -e MYSQL_ROOT_PASSWORD = secret123 -p 3300 :3306 -v /root/mountbind:/var/lib/mysql -d mysql:5.7 Now do ls to the Directory there you can see the containers data ls mountbind Creating docker Volume , use the below command to see all the available options of docker volume docker volume --help Creating a new docker volume with name datadb docker volume create datadb Now run your container with that volume docker run --name db02 -e MYSQL_ROOT_PASSWORD = secret123 -p 3301 :3306 -v datadb:/var/lib/mysql -d mysql:5.7 Now check ls /var/lib/docker/volumes/datadb/_data/ Now for testing Create any file with anyname of your choice, here im creating a file with name milkyway touch /var/lib/docker/volumes/datadb/_data/milkyway Now Login into the container and Verify your file. docker exec -it db02 /bin/bash ls /var/lib/mysql/ Now exit from the container exit If you want to access mysql database with mysql client then follow the below steps sudo apt update sudo apt install mysql-client Now fetch the container IP by doing Docker Inspect docker inspect db02 | grep -i ipaddress Now Connect with that IP mysql -h 172 .17.0.4 -u root -psecret123","title":"Docker"},{"location":"devops/docker-setup/#install-docker-engine-docker-compose-on-ubuntu-centos","text":"Docker Setup Create a file name docker_setup.sh and copy the below script vim docker_setup.sh #!/bin/bash apt --help >>/dev/null if [ $? -eq 0 ] then echo \" INSTALLING DOCKER IN UBUNTU\" echo sudo apt update sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update sudo apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io -y sudo docker run hello-world else echo \" INSTALLING DOCKER IN CENTOS\" echo sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io -y sudo systemctl start docker sudo docker run hello-world fi echo \" Installing Docker Compose\" sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version Give Execute permission for script sudo chmod +x docker_setup.sh Now run the Script ./docker_setup.sh","title":"Install Docker Engine &amp; Docker-Compose on Ubuntu &amp; CentOS"},{"location":"devops/docker-setup/#docker-commands","text":"Docker Images List all images that are locally stored with the Docker Engine docker image ls Build an image from the Dockerfile in the current directory and tag the image docker build -t <imagename>:<tag> Delete an image from the local image store docker image rm <imagename>:<tag> Containers Run a container in interactive mode: docker run -it <imagename>:<tag> Run a container from the Image nginx:latest, name the running container \u201cweb\u201d and expose port 5000 externally, mapped to port 80 inside the container in detached mode. docker run --name web -d -p 5000 :80 nginx:latest Run a detached container in a previously created container network: docker network create <mynetwork> docker run --name web -d --net mynetwork -p 5000 :80 nginx:latest Follow the logs of a specific container: docker logs -f <container name or container container-id> List only active containers docker ps List all containers docker ps -a Stop a container docker stop <container name or container container-id> Stop a container (timeout = 1 second) docker stop -t1 Remove a stopped container docker rm <container name or container container-id> Force stop and remove a container docker rm -f <container name or container container-id> Remove all containers docker rm -f $( docker ps-aq ) Remove all stopped containers docker rm $( docker ps -q -f \u201cstatus = exited\u201d ) Execute a new process in an existing container:Execute and access bash inside a container docker exec -it <container name or container-id> bash To inspect the container docker inspect <container name or container container-id> Share To Establish Connection from local to Remote. login with your Dockerhub Credentials. docker login Pull an image from a registry docker pull <imagename>:<tag> Retag a local image with a new image name and tag docker tag myimage:1.0 myrepo/myimage:2.0 Push an image to a registry. docker push myrepo/myimage:2.0 Dockerfile Sample Dockerfile for Deploying a Staticwebsite. vim Dockerfile FROM centos:latest LABEL \"Author\" = \"saiteja\" LABEL \"Project\" = \"Wave\" RUN yum install httpd wget unzip -y RUN wget https://www.tooplate.com/zip-templates/2121_wave_cafe.zip RUN unzip 2121_wave_cafe.zip RUN cp -r 2121_wave_cafe/* /var/www/html/ CMD [ \"/usr/sbin/httpd\" , \"-D\" , \"FOREGROUND\" ] EXPOSE 80 WORKDIR /var/www/html VOLUME /var/log/httpd Build the image from the Docker file , Here Change my Name with your registery name and Image. docker build -t saitejairrinki/wavecafe:v1 . Run Container From the Image docker run --name wavecafe -d -p 9699 :80 saitejairrinki/wavecafe:v1 Now Access From the Browser, Make sure you have to allow the portnumber in my case 9699 in your security group if you are using cloud VM. Public-IPaddress:9699 Docker Image You can pull my image and you can also run container from my image without creating Dockerfile. docker pull saitejairrinki/wavecafe:v1 docker run --name wavecafe -d -p 9999 :80 saitejairrinki/wavecafe:v1 Now Access From the Browser, Make sure you have to allow the portnumber in my case 9999 in your security group if you are using cloud VM. Public-IPaddress:9999 Docker Volume Creating a Seperate Directory to Store Container data mkdir mountbind Now link your Directory while running the container docker run --name db01 -e MYSQL_ROOT_PASSWORD = secret123 -p 3300 :3306 -v /root/mountbind:/var/lib/mysql -d mysql:5.7 Now do ls to the Directory there you can see the containers data ls mountbind Creating docker Volume , use the below command to see all the available options of docker volume docker volume --help Creating a new docker volume with name datadb docker volume create datadb Now run your container with that volume docker run --name db02 -e MYSQL_ROOT_PASSWORD = secret123 -p 3301 :3306 -v datadb:/var/lib/mysql -d mysql:5.7 Now check ls /var/lib/docker/volumes/datadb/_data/ Now for testing Create any file with anyname of your choice, here im creating a file with name milkyway touch /var/lib/docker/volumes/datadb/_data/milkyway Now Login into the container and Verify your file. docker exec -it db02 /bin/bash ls /var/lib/mysql/ Now exit from the container exit If you want to access mysql database with mysql client then follow the below steps sudo apt update sudo apt install mysql-client Now fetch the container IP by doing Docker Inspect docker inspect db02 | grep -i ipaddress Now Connect with that IP mysql -h 172 .17.0.4 -u root -psecret123","title":"Docker Commands"},{"location":"devops/git/","text":"Git Cheat Sheet \u00b6 GIT BASICS Command Usage git init <directory> Create empty Git repo in specified directory. Run with no arguments to initialize the current directory as a git repository. git clone <repo> Clone repo located at <repo> onto local machine. Original repo can be located on the local filesystem or on a remote machine via HTTP or SSH. git config user.name <name> Define author name to be used for all commits in current repo. Devs commonly use --global flag to set config options for current user. git add <directory> Stage all changes in <directory> for the next commit. Replace <directory> with a <file> to change a specific file. git commit -m \"<message>\" Commit the staged snapshot, but instead of launching a text editor, use as the commit message. git status List which files are staged, unstaged, and untracked. git log Display the entire commit history using the default format. git diff Show unstaged changes between your index and working directory. UNDOING CHANGES Command Usage git revert <commit> Create new commit that undoes all of the changes made in , then apply it to the current branch. git reset <file> Remove from the staging area, but leave the working directory unchanged. This unstages a file without overwriting any changes. git clean -n Shows which files would be removed from working directory.Use the -f flag in place of the -n flag to execute the clean. GIT BRANCHES Command Usage git branch List all of the branches in your repo. Add a argument to create a new branch with the name . git checkout -b <branch> Create and check out a new branch named . Drop the -b flag to checkout an existing branch. git merge <branch> Merge into the current branch. REMOTE REPOSITORIES Command Usage git remote add <name> <url> Create a new connection to a remote repo. After adding a remote,you can use as a shortcu for in other commands. git fetch <remote> <branch> Fetches a specific , from the repo. Leave off to fetch all remote refs. git pull Fetch the specified remote\u2019s copy of current branch and immediately merge it into the local copy. git push <remote> <branch> Push the branch to , along with necessary commits and objects. Creates named branch in the remote repo if it doesn\u2019t exist. GIT RESET Command Usage git reset Reset staging area to match most recent commit, but leave the working directory unchanged. git reset --hard Reset staging area and working directory to match most recent commit and overwrites all changes in the working directory. git reset <commit> Move the current branch tip backward to , reset the staging area to match, but leave the working directory alone. git reset --hard <commit> Same as previous, but resets both the staging area & working directory to match. Deletes uncommitted changes, and all commits after . GIT PULL Command Usage git pull --rebase <remote> Fetch the remote\u2019s copy of current branch and rebases it into the localcopy. Uses git rebase instead of merge to integrate the branches. GIT PUSH Command Usage git push <remote> --force Forces the git push even if it results in a non-fast-forward merge. Do not use the --force flag unless you\u2019re absolutely sure you know what you\u2019re doing. git push <remote> --all Push all of your local branches to the specified remote. git push <remote> --tags Tags aren\u2019t automatically pushed when you push a branch or use the --all flag. The --tags flag sends all of your local tags to the remote repo.","title":"GIT"},{"location":"devops/git/#git-cheat-sheet","text":"GIT BASICS Command Usage git init <directory> Create empty Git repo in specified directory. Run with no arguments to initialize the current directory as a git repository. git clone <repo> Clone repo located at <repo> onto local machine. Original repo can be located on the local filesystem or on a remote machine via HTTP or SSH. git config user.name <name> Define author name to be used for all commits in current repo. Devs commonly use --global flag to set config options for current user. git add <directory> Stage all changes in <directory> for the next commit. Replace <directory> with a <file> to change a specific file. git commit -m \"<message>\" Commit the staged snapshot, but instead of launching a text editor, use as the commit message. git status List which files are staged, unstaged, and untracked. git log Display the entire commit history using the default format. git diff Show unstaged changes between your index and working directory. UNDOING CHANGES Command Usage git revert <commit> Create new commit that undoes all of the changes made in , then apply it to the current branch. git reset <file> Remove from the staging area, but leave the working directory unchanged. This unstages a file without overwriting any changes. git clean -n Shows which files would be removed from working directory.Use the -f flag in place of the -n flag to execute the clean. GIT BRANCHES Command Usage git branch List all of the branches in your repo. Add a argument to create a new branch with the name . git checkout -b <branch> Create and check out a new branch named . Drop the -b flag to checkout an existing branch. git merge <branch> Merge into the current branch. REMOTE REPOSITORIES Command Usage git remote add <name> <url> Create a new connection to a remote repo. After adding a remote,you can use as a shortcu for in other commands. git fetch <remote> <branch> Fetches a specific , from the repo. Leave off to fetch all remote refs. git pull Fetch the specified remote\u2019s copy of current branch and immediately merge it into the local copy. git push <remote> <branch> Push the branch to , along with necessary commits and objects. Creates named branch in the remote repo if it doesn\u2019t exist. GIT RESET Command Usage git reset Reset staging area to match most recent commit, but leave the working directory unchanged. git reset --hard Reset staging area and working directory to match most recent commit and overwrites all changes in the working directory. git reset <commit> Move the current branch tip backward to , reset the staging area to match, but leave the working directory alone. git reset --hard <commit> Same as previous, but resets both the staging area & working directory to match. Deletes uncommitted changes, and all commits after . GIT PULL Command Usage git pull --rebase <remote> Fetch the remote\u2019s copy of current branch and rebases it into the localcopy. Uses git rebase instead of merge to integrate the branches. GIT PUSH Command Usage git push <remote> --force Forces the git push even if it results in a non-fast-forward merge. Do not use the --force flag unless you\u2019re absolutely sure you know what you\u2019re doing. git push <remote> --all Push all of your local branches to the specified remote. git push <remote> --tags Tags aren\u2019t automatically pushed when you push a branch or use the --all flag. The --tags flag sends all of your local tags to the remote repo.","title":"Git Cheat Sheet"},{"location":"devops/jenkins/","text":"Jenkins \u00b6","title":"Jenkins"},{"location":"devops/jenkins/#jenkins","text":"","title":"Jenkins"},{"location":"devops/kops/","text":"Creating Kubernetes Cluster with KOPS \u00b6 Install AWS CLI apt update && apt install awscli -y Configure AWS CLI with IAM user Credentials with specific Region aws configure Note If you are using AWS Instance better to use IAM Role than Creating User with Access-key Check Whether AWS CLI Commands Working or not aws s3 ls Generate SSH Keys ssh-keygen Install kubectl binary with curl on Linux \u00b6 Download the latest release with the command: curl -LO \"https://dl.k8s.io/release/ $( curl -L -s https://dl.k8s.io/release/stable.txt ) /bin/linux/amd64/kubectl\" Install kubectl sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl kubectl version --client Installing Kubernetes with kops \u00b6 Download the latest release with the command: curl -LO https://github.com/kubernetes/kops/releases/download/ $( curl -s https://api.github.com/repos/kubernetes/kops/releases/lates | grep tag_name | cut -d '\"' -f 4 ) /kops-linux-amd64 Make the kops binary executable chmod +x kops-linux-amd64 Move the kops binary in to your PATH. sudo mv kops-linux-amd64 /usr/local/bin/kops kops Creating K8s Cluster with KOPS \u00b6 Kops commands to setup k8s cluster:- \u00b6 kops create cluster --name = saiteja.irrinki.xyz --state = s3://<s3 bucket> --zones = ap-south-1a,ap-south-1b --node-count = 2 --node-size = t2.micro --master-size = t2.micro --dns-zone = saiteja.irrinki.xyz --node-volume-size = 8 --master-volume-size = 8 It will create configuration of kops kops update cluster --name = saiteja.irrinki.xyz --state = s3://<s3 bucket> --yes --admin It will create kopsdata in S3 bucket. It start creating a cluster & it takes 10 mins kops validate cluster -- name = saiteja . irrinki . xyz -- state = s3 : //<s3 bucket> It shows ur cluster is ready To Delete Cluster kops delete cluster -- name = saiteja . irrinki . xyz -- state = s3 : //<s3 bucket> --yes","title":"KOPS"},{"location":"devops/kops/#creating-kubernetes-cluster-with-kops","text":"Install AWS CLI apt update && apt install awscli -y Configure AWS CLI with IAM user Credentials with specific Region aws configure Note If you are using AWS Instance better to use IAM Role than Creating User with Access-key Check Whether AWS CLI Commands Working or not aws s3 ls Generate SSH Keys ssh-keygen","title":"Creating Kubernetes Cluster with KOPS"},{"location":"devops/kops/#install-kubectl-binary-with-curl-on-linux","text":"Download the latest release with the command: curl -LO \"https://dl.k8s.io/release/ $( curl -L -s https://dl.k8s.io/release/stable.txt ) /bin/linux/amd64/kubectl\" Install kubectl sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl kubectl version --client","title":"Install kubectl binary with curl on Linux"},{"location":"devops/kops/#installing-kubernetes-with-kops","text":"Download the latest release with the command: curl -LO https://github.com/kubernetes/kops/releases/download/ $( curl -s https://api.github.com/repos/kubernetes/kops/releases/lates | grep tag_name | cut -d '\"' -f 4 ) /kops-linux-amd64 Make the kops binary executable chmod +x kops-linux-amd64 Move the kops binary in to your PATH. sudo mv kops-linux-amd64 /usr/local/bin/kops kops","title":"Installing Kubernetes with kops"},{"location":"devops/kops/#creating-k8s-cluster-with-kops","text":"","title":"Creating K8s Cluster with KOPS"},{"location":"devops/kops/#kops-commands-to-setup-k8s-cluster-","text":"kops create cluster --name = saiteja.irrinki.xyz --state = s3://<s3 bucket> --zones = ap-south-1a,ap-south-1b --node-count = 2 --node-size = t2.micro --master-size = t2.micro --dns-zone = saiteja.irrinki.xyz --node-volume-size = 8 --master-volume-size = 8 It will create configuration of kops kops update cluster --name = saiteja.irrinki.xyz --state = s3://<s3 bucket> --yes --admin It will create kopsdata in S3 bucket. It start creating a cluster & it takes 10 mins kops validate cluster -- name = saiteja . irrinki . xyz -- state = s3 : //<s3 bucket> It shows ur cluster is ready To Delete Cluster kops delete cluster -- name = saiteja . irrinki . xyz -- state = s3 : //<s3 bucket> --yes","title":"Kops commands to setup k8s cluster:-"},{"location":"devops/kubeadm/","text":"Kubeadm \u00b6 For this activity, deploy minimum 2 AWS instances with the Security groups All traffic is enabled between the instances Node Name Instance Details Resources Master Node -t2.medium 4GB Ram , 2 CPU Worker Node -t2.micro 1GB Ram , 1 CPU Preparing the Master and Worker nodes for kubeadm \u00b6 Execute the below Commands on both Master & Worker Nodes Change the hostname for nodes as master & worker Installing Docker: \u00b6 Add the Docker repository key and Docker repository. curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - add-apt-repository \\ \"deb https://download.docker.com/linux/ $( . /etc/os-release ; echo \" $ID \" ) \\ $( lsb_release -cs ) \\ stable\" Update the list of packages and install the docker apt-get update apt-get install -y docker-ce echo '{\"exec-opts\": [\"native.cgroupdriver=systemd\"]}' | sudo tee /etc/docker/daemon.json systemctl daemon-reload systemctl restart docker systemctl enable docker Installing kubeadm, kublet, and kubectl: \u00b6 Add the Google repository key and Google repository curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - vim /etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io kubernetes-xenial main Update the list of packages. And install kubelet, kubeadm and kubectl. apt-get update apt-get install kubelet kubeadm kubectl -y Disable the swap. swapoff -a Setup Master Node to Connect with Worker Nodes sed -i '/ swap / s/^/#/' /etc/fstab echo NODENAME = $( hostname -s ) Now Create a Directory Name .kube in the master node home directory mkdir .kube Copy the Default conf file to the .kube directory cp /etc/kubernetes/admin.conf .kube/config Replace the Ip address with your Instance Private Ip Address and set pod Network kubeadm init --apiserver-advertise-address = 172 .31.85.246 --apiserver-cert-extra-sans = 172 .31.85.246 --pod-network-cidr = 10 .0.0.0/16 After Executing kubeadm init command you will get one command as output that need to execute on worker nodes kubeadm join 172 .31.85.246:6443 --token n6v08z.53b057pfwnj8mq10 --discovery-token-ca-cert-hash sha256:9e8a38ddfc46c41ecb3317db9fc2145f70bddbdd2c6b8091fbdbab18e1dbcb19 Configuring the Calico kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml Now check Kubectl commands kubectl get node Now test the cluster kubectl run pod --image = nginx kubectl get pod kubectl get pod -o wide","title":"Kubeadm"},{"location":"devops/kubeadm/#kubeadm","text":"For this activity, deploy minimum 2 AWS instances with the Security groups All traffic is enabled between the instances Node Name Instance Details Resources Master Node -t2.medium 4GB Ram , 2 CPU Worker Node -t2.micro 1GB Ram , 1 CPU","title":"Kubeadm"},{"location":"devops/kubeadm/#preparing-the-master-and-worker-nodes-for-kubeadm","text":"Execute the below Commands on both Master & Worker Nodes Change the hostname for nodes as master & worker","title":"Preparing the Master and Worker nodes for kubeadm"},{"location":"devops/kubeadm/#installing-docker","text":"Add the Docker repository key and Docker repository. curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - add-apt-repository \\ \"deb https://download.docker.com/linux/ $( . /etc/os-release ; echo \" $ID \" ) \\ $( lsb_release -cs ) \\ stable\" Update the list of packages and install the docker apt-get update apt-get install -y docker-ce echo '{\"exec-opts\": [\"native.cgroupdriver=systemd\"]}' | sudo tee /etc/docker/daemon.json systemctl daemon-reload systemctl restart docker systemctl enable docker","title":"Installing Docker:"},{"location":"devops/kubeadm/#installing-kubeadm-kublet-and-kubectl","text":"Add the Google repository key and Google repository curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - vim /etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io kubernetes-xenial main Update the list of packages. And install kubelet, kubeadm and kubectl. apt-get update apt-get install kubelet kubeadm kubectl -y Disable the swap. swapoff -a Setup Master Node to Connect with Worker Nodes sed -i '/ swap / s/^/#/' /etc/fstab echo NODENAME = $( hostname -s ) Now Create a Directory Name .kube in the master node home directory mkdir .kube Copy the Default conf file to the .kube directory cp /etc/kubernetes/admin.conf .kube/config Replace the Ip address with your Instance Private Ip Address and set pod Network kubeadm init --apiserver-advertise-address = 172 .31.85.246 --apiserver-cert-extra-sans = 172 .31.85.246 --pod-network-cidr = 10 .0.0.0/16 After Executing kubeadm init command you will get one command as output that need to execute on worker nodes kubeadm join 172 .31.85.246:6443 --token n6v08z.53b057pfwnj8mq10 --discovery-token-ca-cert-hash sha256:9e8a38ddfc46c41ecb3317db9fc2145f70bddbdd2c6b8091fbdbab18e1dbcb19 Configuring the Calico kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml Now check Kubectl commands kubectl get node Now test the cluster kubectl run pod --image = nginx kubectl get pod kubectl get pod -o wide","title":"Installing kubeadm, kublet, and kubectl:"},{"location":"devops/shellscripting/","text":"Shell Scripting \u00b6 If Condition \u00b6 If Condition If Else Condition Elif Condition Example #!/bin/bash < Command > if [ < condition > ] then < Commands to Execute > < print Messges with echo > fi #!/bin/bash < Command > if [ < condition > ] then < Commands to Execute > < print Messges with echo > else < Commands to Execute > < print Messges with echo > fi #!/bin/bash < Command > if [ < condition > ] then < Commands to Execute > < print Messges with echo > elif then < Commands to Execute > < print Messges with echo > else < Commands to Execute > < print Messges with echo > fi #!/bin/bash apt -- help >> / dev / null if [ $ ? - eq 0 ] then echo \" This is Ubuntu Operating System\" else echo \" This is CentOS Operating System\" fi Reference Link How to program with Bash https://opensource.com/article/19/10/programming-bash-logical-operators-shell-expansions For Loop \u00b6 For Loop Example #!/bin/bash for < variable > in < list > do < command > done #For loop example for adding users with name alpha beta gamma #!/bin/bash for USER in alpha beta gamma do echo \"adding user $USER to system\" sudo useradd $USER done While Loop \u00b6 While Loop While Loop Example #!/bin/bash while [ < condition > ] do < command > done #!/bin/bash #Here variable \"a\" is speed a = 0 echo \"starting the Engine\" while [ $a - le 100 ] do sleep 1 echo \"Current Speed $a\" a = $ (( $a + 10 )) done Shell Script For Setting Up Website \u00b6 Ubuntu Centos Using Variables Using If Else Condition #!/bin/bash sudo apt install wget net - tools unzip apache2 - y sudo systemctl start apache2 sudo systemctl enable apache2 sudo mkdir - p / tmp / webfiles cd / tmp / webfiles sudo wget https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118 _chilling_cafe . zip sudo cp - r 2118 _chilling_cafe /* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart apache2 #!/bin/bash sudo yum install wget net - tools unzip httpd - y sudo systemctl start httpd sudo systemctl enable httpd sudo mkdir - p / tmp / webfiles cd / tmp / webfiles sudo wget https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118 _chilling_cafe . zip sudo cp - r 2118 _chilling_cafe /* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart httpd #!/bin/bash #Weibsite setup #Adding variables :-) URL = https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip SRV = httpd PKG = yum FILE = 2118 _chilling_cafe echo \" Installing the Services & Extractors\" echo sudo $PKG install $SRV wget unzip - y >> / dev / null echo \"Start & Enabling the Services\" echo sudo systemctl start $SRV sudo systemctl enable $SRV echo \"Downloading the zip file from tooplate.com\" echo sudo mkdir - p / tmp / webfiles cd / tmp / webfiles echo sudo wget $URL >> / dev / null echo \"extracting the files \" echo unzip - o $FILE . zip >> / dev / null echo \"copying the extracted file into html\" echo sudo cp - r $FILE /* /var/www/html >> /dev/null echo \"Restarting the Services\" sudo systemctl restart $SRV sudo rm -rf /tmp/webfiles sudo systemctl status $SRV | grep Active date #!/bin/bash apt -- help >> / dev / null if [ $ ? - eq 0 ] then sudo apt install wget net - tools unzip apache2 - y sudo systemctl start apache2 sudo systemctl enable apache2 sudo mkdir - p / tmp / webfiles cd / tmp / webfiles sudo wget https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118 _chilling_cafe . zip sudo cp - r 2118 _chilling_cafe /* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart apache2 sudo systemctl status apache2 | grep Active else sudo yum install wget net-tools unzip httpd -y sudo systemctl start httpd sudo systemctl enable httpd sudo mkdir -p /tmp/webfiles cd /tmp/webfiles sudo wget https://www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118_chilling_cafe.zip sudo cp -r 2118_chilling_cafe/* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart httpd sudo systemctl status httpd | grep Active fi","title":"Shell Scripting"},{"location":"devops/shellscripting/#shell-scripting","text":"","title":"Shell Scripting"},{"location":"devops/shellscripting/#if-condition","text":"If Condition If Else Condition Elif Condition Example #!/bin/bash < Command > if [ < condition > ] then < Commands to Execute > < print Messges with echo > fi #!/bin/bash < Command > if [ < condition > ] then < Commands to Execute > < print Messges with echo > else < Commands to Execute > < print Messges with echo > fi #!/bin/bash < Command > if [ < condition > ] then < Commands to Execute > < print Messges with echo > elif then < Commands to Execute > < print Messges with echo > else < Commands to Execute > < print Messges with echo > fi #!/bin/bash apt -- help >> / dev / null if [ $ ? - eq 0 ] then echo \" This is Ubuntu Operating System\" else echo \" This is CentOS Operating System\" fi Reference Link How to program with Bash https://opensource.com/article/19/10/programming-bash-logical-operators-shell-expansions","title":"If Condition"},{"location":"devops/shellscripting/#for-loop","text":"For Loop Example #!/bin/bash for < variable > in < list > do < command > done #For loop example for adding users with name alpha beta gamma #!/bin/bash for USER in alpha beta gamma do echo \"adding user $USER to system\" sudo useradd $USER done","title":"For Loop"},{"location":"devops/shellscripting/#while-loop","text":"While Loop While Loop Example #!/bin/bash while [ < condition > ] do < command > done #!/bin/bash #Here variable \"a\" is speed a = 0 echo \"starting the Engine\" while [ $a - le 100 ] do sleep 1 echo \"Current Speed $a\" a = $ (( $a + 10 )) done","title":"While Loop"},{"location":"devops/shellscripting/#shell-script-for-setting-up-website","text":"Ubuntu Centos Using Variables Using If Else Condition #!/bin/bash sudo apt install wget net - tools unzip apache2 - y sudo systemctl start apache2 sudo systemctl enable apache2 sudo mkdir - p / tmp / webfiles cd / tmp / webfiles sudo wget https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118 _chilling_cafe . zip sudo cp - r 2118 _chilling_cafe /* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart apache2 #!/bin/bash sudo yum install wget net - tools unzip httpd - y sudo systemctl start httpd sudo systemctl enable httpd sudo mkdir - p / tmp / webfiles cd / tmp / webfiles sudo wget https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118 _chilling_cafe . zip sudo cp - r 2118 _chilling_cafe /* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart httpd #!/bin/bash #Weibsite setup #Adding variables :-) URL = https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip SRV = httpd PKG = yum FILE = 2118 _chilling_cafe echo \" Installing the Services & Extractors\" echo sudo $PKG install $SRV wget unzip - y >> / dev / null echo \"Start & Enabling the Services\" echo sudo systemctl start $SRV sudo systemctl enable $SRV echo \"Downloading the zip file from tooplate.com\" echo sudo mkdir - p / tmp / webfiles cd / tmp / webfiles echo sudo wget $URL >> / dev / null echo \"extracting the files \" echo unzip - o $FILE . zip >> / dev / null echo \"copying the extracted file into html\" echo sudo cp - r $FILE /* /var/www/html >> /dev/null echo \"Restarting the Services\" sudo systemctl restart $SRV sudo rm -rf /tmp/webfiles sudo systemctl status $SRV | grep Active date #!/bin/bash apt -- help >> / dev / null if [ $ ? - eq 0 ] then sudo apt install wget net - tools unzip apache2 - y sudo systemctl start apache2 sudo systemctl enable apache2 sudo mkdir - p / tmp / webfiles cd / tmp / webfiles sudo wget https : //www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118 _chilling_cafe . zip sudo cp - r 2118 _chilling_cafe /* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart apache2 sudo systemctl status apache2 | grep Active else sudo yum install wget net-tools unzip httpd -y sudo systemctl start httpd sudo systemctl enable httpd sudo mkdir -p /tmp/webfiles cd /tmp/webfiles sudo wget https://www.tooplate.com/zip-templates/2118_chilling_cafe.zip unzip 2118_chilling_cafe.zip sudo cp -r 2118_chilling_cafe/* /var/www/html/ sudo rm -r /tmp/webfiles sudo systemctl restart httpd sudo systemctl status httpd | grep Active fi","title":"Shell Script For Setting Up Website"},{"location":"devops/vagrant/","text":"Vagrant \u00b6 Requirements Virtualbox Vagrant Installing Virtualbox in the Host Machine \u00b6 Windows Ubuntu Linux Download link https : //download.virtualbox.org/virtualbox/6.1.30/VirtualBox-6.1.30-148432-Win.exe Through Command line sudo apt update sudo apt install virtualbox Installing Vagrant in the Host Machine \u00b6 Windows Ubuntu Linux Download link https : //www.vagrantup.com/downloads Through Command line sudo apt update sudo apt install vagrant Creating a Common Directory for all VM's \u00b6 Create a Directory with name vagrantvms mkdir vagrantvms Change Directory to vagrantvms cd vagrantvms To Bring up VM \u00b6 Ubuntu CentOS Create a Directory name ubuntu mkdir ubuntu Change Directory to ubuntu cd ubuntu Initialize Ubuntu VM vagrant init ubuntu/bionic64 Now Bring up your Ubuntu VM vagrant up Once your VM is up then login to your vm vagrant ssh Now you can see the prompt of ubuntu machine, If you wanna exit type exit Create a Directory name centos mkdir centos Change Directory to centos cd centos Initialize centos VM vagrant init geerlingguy/centos7 Now Bring up your centos VM vagrant up Once your VM is up then login to your vm vagrant ssh Now you can see the prompt of centos machine, If you wanna exit type exit To Init Specific Vagrant box https://app.vagrantup.com/boxes/search Multi VMS Vagrantfile Vagrant . configure ( \"2\" ) do | config | config . hostmanager . enabled = true config . hostmanager . manage_host = true ### Nginx VM ### config . vm . define \"web01\" do | web01 | web01 . vm . box = \"ubuntu/bionic64\" web01 . vm . hostname = \"web01\" web01 . vm . network \"private_network\" , ip : \"192.168.33.11\" web01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" end ### tomcat vm ### config . vm . define \"app01\" do | app01 | app01 . vm . box = \"geerlingguy/centos7\" app01 . vm . hostname = \"app01\" app01 . vm . network \"private_network\" , ip : \"192.168.33.12\" app01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" app01 . vm . provider \"virtualbox\" do | vb | vb . memory = \"1024\" end app01 . vm . provision \"shell\" , inline : <<- SHELL # yum update -y yum install epel-release -y SHELL end ### RabbitMQ vm #### config . vm . define \"rmq01\" do | rmq01 | rmq01 . vm . box = \"geerlingguy/centos7\" rmq01 . vm . hostname = \"rmq01\" rmq01 . vm . network \"private_network\" , ip : \"192.168.33.16\" rmq01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" rmq01 . vm . provision \"shell\" , inline : <<- SHELL # yum update -y #yum install epel-release -y # yum install wget -y SHELL end ; f . , v / ### Memcache vm #### config . vm . define \"mc01\" do | mc01 | mc01 . vm . box = \"geerlingguy/centos7\" mc01 . vm . hostname = \"mc01\" mc01 . vm . network \"private_network\" , ip : \"192.168.33.14\" mc01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" mc01 . vm . provision \"shell\" , inline : <<- SHELL yum install epel-release -y SHELL end ### DB vm #### config . vm . define \"db01\" do | db01 | db01 . vm . box = \"geerlingguy/centos7\" db01 . vm . hostname = \"db01\" db01 . vm . network \"private_network\" , ip : \"192.168.33.15\" db01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" db01 . vm . provision \"shell\" , inline : <<- SHELL # yum update -y yum install epel-release -y SHELL end end","title":"Vagrant"},{"location":"devops/vagrant/#vagrant","text":"Requirements Virtualbox Vagrant","title":"Vagrant"},{"location":"devops/vagrant/#installing-virtualbox-in-the-host-machine","text":"Windows Ubuntu Linux Download link https : //download.virtualbox.org/virtualbox/6.1.30/VirtualBox-6.1.30-148432-Win.exe Through Command line sudo apt update sudo apt install virtualbox","title":"Installing Virtualbox in the Host Machine"},{"location":"devops/vagrant/#installing-vagrant-in-the-host-machine","text":"Windows Ubuntu Linux Download link https : //www.vagrantup.com/downloads Through Command line sudo apt update sudo apt install vagrant","title":"Installing Vagrant in the Host Machine"},{"location":"devops/vagrant/#creating-a-common-directory-for-all-vms","text":"Create a Directory with name vagrantvms mkdir vagrantvms Change Directory to vagrantvms cd vagrantvms","title":"Creating a Common Directory for all VM's"},{"location":"devops/vagrant/#to-bring-up-vm","text":"Ubuntu CentOS Create a Directory name ubuntu mkdir ubuntu Change Directory to ubuntu cd ubuntu Initialize Ubuntu VM vagrant init ubuntu/bionic64 Now Bring up your Ubuntu VM vagrant up Once your VM is up then login to your vm vagrant ssh Now you can see the prompt of ubuntu machine, If you wanna exit type exit Create a Directory name centos mkdir centos Change Directory to centos cd centos Initialize centos VM vagrant init geerlingguy/centos7 Now Bring up your centos VM vagrant up Once your VM is up then login to your vm vagrant ssh Now you can see the prompt of centos machine, If you wanna exit type exit To Init Specific Vagrant box https://app.vagrantup.com/boxes/search Multi VMS Vagrantfile Vagrant . configure ( \"2\" ) do | config | config . hostmanager . enabled = true config . hostmanager . manage_host = true ### Nginx VM ### config . vm . define \"web01\" do | web01 | web01 . vm . box = \"ubuntu/bionic64\" web01 . vm . hostname = \"web01\" web01 . vm . network \"private_network\" , ip : \"192.168.33.11\" web01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" end ### tomcat vm ### config . vm . define \"app01\" do | app01 | app01 . vm . box = \"geerlingguy/centos7\" app01 . vm . hostname = \"app01\" app01 . vm . network \"private_network\" , ip : \"192.168.33.12\" app01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" app01 . vm . provider \"virtualbox\" do | vb | vb . memory = \"1024\" end app01 . vm . provision \"shell\" , inline : <<- SHELL # yum update -y yum install epel-release -y SHELL end ### RabbitMQ vm #### config . vm . define \"rmq01\" do | rmq01 | rmq01 . vm . box = \"geerlingguy/centos7\" rmq01 . vm . hostname = \"rmq01\" rmq01 . vm . network \"private_network\" , ip : \"192.168.33.16\" rmq01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" rmq01 . vm . provision \"shell\" , inline : <<- SHELL # yum update -y #yum install epel-release -y # yum install wget -y SHELL end ; f . , v / ### Memcache vm #### config . vm . define \"mc01\" do | mc01 | mc01 . vm . box = \"geerlingguy/centos7\" mc01 . vm . hostname = \"mc01\" mc01 . vm . network \"private_network\" , ip : \"192.168.33.14\" mc01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" mc01 . vm . provision \"shell\" , inline : <<- SHELL yum install epel-release -y SHELL end ### DB vm #### config . vm . define \"db01\" do | db01 | db01 . vm . box = \"geerlingguy/centos7\" db01 . vm . hostname = \"db01\" db01 . vm . network \"private_network\" , ip : \"192.168.33.15\" db01 . vm . synced_folder \"../vprofile-code\" , \"/vprofile-vm-data\" db01 . vm . provision \"shell\" , inline : <<- SHELL # yum update -y yum install epel-release -y SHELL end end","title":"To Bring up VM"}]}